# @package _global_
defaults:
  - /model: wikitext2/small

task:
  name: wikitext2-classification

training:
  num_epochs: 150  # Updated
  per_device_batch_size: 32  # Updated
  per_device_eval_batch_size: 256
  num_workers: 96
  cut_mix: 0.0
  pad_unit: 100
  no_time_information: true
  loss_type: one_hot_cross_entropy

optimizer:
  ssm_base_lr: 3.4808848912987e-05  # Updated
  lr_factor: 13  # Updated
  warmup_epochs: 1
  ssm_weight_decay: 0.08940075624800575  # Updated
  weight_decay: 0.18156033226111873  # Updated
  schedule: cosine
  accumulation_steps: 1
  proj_weight_decay: 0.25632236597393  # Updated
